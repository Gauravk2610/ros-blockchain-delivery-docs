SLAM Implementation
#####################

In this section, we will look at how we implemented the SLAM in our project.

Mapping
********

Gmapping, which was used in this project, is a laser-based SLAM (Simultaneous Localization and Mapping) algorithm that builds a 2d map.
It uses laser scan data and odometry data from the robot to feed a highly efficient Rao-Blackwellized particle filer to learn grid maps from laser range data.
The laser scan is generated by taking the point cloud from the 3D sensor and grabbing points from an “eye-level” prespective of the robot. It does not use any RGB data, or any full depth data.

The package contains a node called slam_gmapping. This node will generate the 2D map of our environment and we can then save the map for further use.

.. seealso::

    More information can be found in `ROS Wiki Gmapping <http://wiki.ros.org/gmapping>`_

Localization
*************

For localizing the robot in our environmnet, AMCL was used which is a probabilistic localization system for a robot moving in 2D. 
It implements the adaptive Monte Carlo localization approach which uses a particle filter to track the pose of a robot against a known map. 

AMCL transforms incoming laser scans to the odometry frame. on receipt of the first laser scan, amcl looks up the transform between the laser's frame and the base frame, and latches it forever. During operation amcl estimates the transformation of the base frame in respect to the global frame but it only publishes the transform between the global frame and the odometry frame. Essentially, this transform accounts for the drift that occurs using Dead Reckoning.

.. image:: ../_static/images/amcl_localization.png
  :width: 600
  :alt: Localization

.. seealso::

    More information can be found in `ROS Wiki AMCL <http://wiki.ros.org/amcl>`_

Navigation
***********



.. seealso::

    More information can be found in `ROS Wiki Global Planner <http://wiki.ros.org/global_planner>`_
